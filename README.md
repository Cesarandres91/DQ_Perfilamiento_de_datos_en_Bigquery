# Sistema de Perfilamiento de Datos para BigQuery

## Descripci√≥n del Proyecto
Este repositorio contiene un marco de trabajo automatizado dise√±ado para crear perfiles de datos de tablas almacenadas en Google BigQuery. Utiliza Python para iterar sobre un conjunto de reglas de datos definidas en una hoja de Excel, generando scripts SQL din√°micamente para el an√°lisis de calidad de datos en BigQuery.

## :bar_chart: Mejorando la Calidad y An√°lisis de Datos en la Nube con una Herramienta de Perfilamiento de Datos
Buenas tardes, distinguidos colegas y l√≠deres en el campo de la tecnolog√≠a y an√°lisis de datos. Hoy tengo el placer de compartir con ustedes una innovadora soluci√≥n que he desarrollado para mejorar la calidad y el an√°lisis de los datos en entornos de la nube.

## :file_folder: Flexibilidad en la Carga de Datos
Esta herramienta, dise√±ada y codificada meticulosamente, facilita el perfilamiento de datos mediante una serie de cargas de datos flexibles y personalizables desde diversas fuentes como archivos CSV, Excel, y directamente desde Google Sheets. Esta capacidad de adaptarse a m√∫ltiples formatos de entrada es fundamental en entornos din√°micos donde la agilidad y la precisi√≥n son cruciales.

## :mag_right: An√°lisis Detallado y Personalizado
Adem√°s, el c√≥digo incorpora funcionalidades avanzadas para generar consultas SQL detalladas y espec√≠ficas que se ejecutan en BigQuery. Estas consultas no solo contabilizan registros totales y nulos, sino que tambi√©n eval√∫an la integridad y la distribuci√≥n de los datos, incluyendo la identificaci√≥n de valores extremos y la realizaci√≥n de c√°lculos estad√≠sticos como promedios y conteos condicionales. Esto es esencial para garantizar que los datos no solo sean precisos, sino tambi√©n √∫tiles para tomar decisiones informadas.

## :hammer_and_wrench: Automatizaci√≥n y Manejo Eficiente
Una de las caracter√≠sticas m√°s innovadoras de este c√≥digo es su capacidad para automatizar el desglose de grandes conjuntos de datos en m√∫ltiples partes, facilitando as√≠ su manejo y an√°lisis. Cada segmento del an√°lisis puede ser exportado y compartido en tiempo real, permitiendo una colaboraci√≥n efectiva y una revisi√≥n continua de los resultados.

## :rocket: Impulsando Decisiones Informadas
Esta herramienta no solo optimiza los procesos de trabajo existentes sino que tambi√©n abre nuevas oportunidades para explorar datos complejos de manera m√°s eficiente en la nube. Al mejorar continuamente la calidad de los datos y proporcionar an√°lisis profundos y accesibles, facilitamos la toma de decisiones basadas en evidencias s√≥lidas y contribuimos al avance de nuestras empresas y clientes en la era digital.

## :handshake: Invitaci√≥n a Colaborar
Invito a todos los interesados en mejorar la calidad de sus datos y eficientizar sus procesos anal√≠ticos a conectarse conmigo para explorar posibles colaboraciones y oportunidades profesionales. Juntos, podemos transformar la manera en que interactuamos con los datos y liderar la pr√≥xima ola de innovaciones en la anal√≠tica de datos.

## :sparkles: Gracias por su atenci√≥n y espero poder conectar y colaborar con muchos de ustedes en el futuro pr√≥ximo. :sparkles:

## üìÅ Estructura de Archivos

Aseg√∫rate de tener estos archivos en tu directorio de trabajo:
- `perfilamiento_proyecto_dq_desktop.py`:  Este archivo contiene todo el c√≥digo necesario para ejecutar las consultas de perfilamiento en el escritorio con Python.
- `perfilamiento_proyecto_dq_gcolab.py`:  Este archivo contiene todo el c√≥digo necesario para ejecutar las consultas de perfilamiento en google colab.
- `plantilla_perfilamiento.csv`: Una plantilla CSV que define el esquema de los datos a analizar.
  
- ## Uso
- Modifica el archivo `perfilamiento_datos.csv` con los campos y par√°metros deseados para el perfilamiento.
- Ejecuta el script `perfilamiento_proyecto_dq.py` para generar las consultas SQL

## üó∫Ô∏è Gu√≠a Paso a Paso

### Paso 1: Preparar la Plantilla de Datos

1. Abre el archivo `perfilamiento_datos.csv` en un editor de texto o en una hoja de c√°lculo.
2. Edita las columnas seg√∫n los datos que necesitas perfilar:
   - **CAMPO**: Nombre del campo a analizar.
   - **TIPO**: Tipo de dato del campo (e.g., STRING, INTEGER).
   - **PARTICION**: Nombre de la columna de partici√≥n.
   - **TABLA**: Nombre de la tabla donde se encuentra el campo.
   - **Fecha_desde**: Fecha de inicio para el filtro de la consulta.
   - **Fecha_hasta**: Fecha de fin para el filtro de la consulta.

     Ejemplo del archivo:
     ![image](https://github.com/Cesarandres91/DQ_Perfilamiento_de_datos_en_Bigquery/assets/102868086/8fcbe9e9-3378-48cb-bdcc-04038de2ae87)


### Paso 2: Configuraci√≥n del Entorno

Aseg√∫rate de que tu entorno Python est√° configurado correctamente, siempre puedes ejecutarlo en googlecolab para evitar quebraderos de cabeza y verifica que tienes las credenciales necesarias para acceder a Google BigQuery.

### Paso 3: Ejecutar el Script

1. Abre tu terminal o l√≠nea de comandos.
2. Navega hasta el directorio donde se encuentran los archivos `perfilamiento_proyecto_dq.py` y `perfilamiento_datos.csv`.
3. Ejecuta el siguiente comando:
   ```bash
    python perfilamiento_proyecto_dq.py
   ```
El script leer√° la plantilla, generar√° las consultas SQL en un archivo de texto que podr√°s copiar y pegar en BigQuery.
Ejemplo Output con archivo Sample de Twitch:

Ejemplo Query generada: 
``` Ejemplo_Query_generada.txt ```
![image](https://github.com/Cesarandres91/DQ_Perfilamiento_de_datos_en_Bigquery/assets/102868086/846bcea7-572f-4f27-be47-d41e990c5c3f)

PD: Las consultas est√°n particionadas en varios archivos en caso de que la cantidad de campos sea alta, esto es basado solo en mi propia experiencia en cuanto a rendimiento, manejo de recursos y control de limites que establece BigQuery, pero puedes modificarlo directamente en el c√≥digo en caso de que no lo necesites.

### Paso 4: Revisar los Resultados
Revisa los resultados de las consultas que se mostrar√°n en la salida est√°ndar o en los archivos de salida especificados en el script.
Analiza los datos para entender mejor la calidad y estructura de los datos en tu base de datos BigQuery.

![image](https://github.com/Cesarandres91/DQ_Perfilamiento_de_datos_en_Bigquery/assets/102868086/a87a847e-3a5a-44b0-ab85-20997af8381a)

![image](https://github.com/Cesarandres91/DQ_Perfilamiento_de_datos_en_Bigquery/assets/102868086/0121ddfc-0de8-41c9-a449-9ea17c2589eb)

Ya con estos datos, solo queda generar las gr√°ficas con nuestra herramientas de inteligencia de negocio preferida o plataforma de visualizaci√≥n de datos,
en este caso para no depender de ninguna librer√≠a las gener√© utilizando python, con estas librer√≠as:
```
import matplotlib.pyplot as plt
import seaborn as sns
# Configurar estilo de Seaborn
sns.set(style="whitegrid")
 ```
![Nulos](https://github.com/Cesarandres91/DQ_Perfilamiento_de_datos_en_Bigquery/assets/102868086/60a98605-165d-4d1a-87d0-7d6584313fb9)

![Distintos](https://github.com/Cesarandres91/DQ_Perfilamiento_de_datos_en_Bigquery/assets/102868086/4fad40d0-29c3-4a22-8047-16ecae79c166)

![Largo_maximo](https://github.com/Cesarandres91/DQ_Perfilamiento_de_datos_en_Bigquery/assets/102868086/2888a304-eccc-41dc-ab4e-78890a18537d)

![Largo_minimo](https://github.com/Cesarandres91/DQ_Perfilamiento_de_datos_en_Bigquery/assets/102868086/a735da08-c44f-41e0-8617-9fc2e050acc8)


üßê Soluci√≥n de Problemas
Si encuentras errores durante la ejecuci√≥n, verifica lo siguiente:
Que las credenciales de BigQuery est√°n configuradas correctamente.
Que los nombres de las columnas en perfilamiento_datos.csv coinciden exactamente con los de la base de datos.
Que tienes permisos suficientes en BigQuery para ejecutar consultas y acceder a las tablas especificadas.

## Caracter√≠sticas
- **Generaci√≥n Autom√°tica de Consultas SQL**: Scripts de Python leen especificaciones desde una hoja de Excel y generan consultas SQL.
- **Perfilamiento Personalizable**: Permite la personalizaci√≥n completa del perfilamiento basado en par√°metros definidos en la hoja de Excel.
- **Reportes de Calidad de Datos**: Genera m√©tricas de calidad de datos como registros correctos, errores y umbrales de calidad.

## Pre-requisitos
- Python 3.8 o superior.
- Acceso a Google BigQuery.
- Google Colab o un entorno Python local configurado.
- Paquete `pandas` instalado para la manipulaci√≥n de datos.
- Credenciales de Google Cloud con permisos adecuados para leer y ejecutar consultas en BigQuery.

## Configuraci√≥n
1. **Clonar el Repositorio**:

2. **Instalaci√≥n de Dependencias**:


3. **Configuraci√≥n de Credenciales de Google Cloud**:
- Aseg√∫rate de tener un archivo de credenciales de servicio de Google Cloud (JSON).
- Establece la variable de entorno `GOOGLE_APPLICATION_CREDENTIALS` apuntando al archivo JSON:
  ```
  export GOOGLE_APPLICATION_CREDENTIALS="path/to/your/credentials.json"
  ```


## Contribuci√≥n
Para contribuir al proyecto, por favor sigue los siguientes pasos:
- **Fork el Repositorio**: Haz un fork del proyecto a tu cuenta de GitHub.
- **Crea una Rama**: Crea una rama para tus cambios.
- **Haz tus Cambios**: A√±ade o mejora funcionalidades.
- **Env√≠a un Pull Request**: Env√≠a un PR para integrar tus cambios al repositorio principal.

## Licencia
Este proyecto est√° licenciado bajo la Licencia MIT - ver el archivo `LICENSE` para m√°s detalles.


