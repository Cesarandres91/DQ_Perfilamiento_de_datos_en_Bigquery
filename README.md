# Data Quality - Perfilamiento de datos (Data Profiling)

## Hi there üëã, I'm Cesar (@Cesarandres91)

- üëÄ I‚Äôm interested in data quality, data science, and data governance.
- üå± I‚Äôm currently improving my skills in data science.
- üíûÔ∏è I‚Äôm looking to collaborate on data governance, quality, science or cybersecurity projects.
- üì´ How to reach me: [LinkedIn](https://www.linkedin.com/in/andreschile/)


Te ser√° muy √∫til si se eres : 
| Position                                                         |
|---------------------------------------------------------------|
| üßë‚Äçüî¨ Cient√≠fico de Datos (Data Scientist)                  |
| üë∑‚Äç‚ôÇÔ∏è Ingeniero de Datos (Data Engineer)                    |
| üìä Analista de Datos (Data Analyst)                          |
| üóÑÔ∏è Administrador de Bases de Datos (Database Administrator)  |
| üèóÔ∏è Arquitecto de Datos (Data Architect)                    |
| üõ†Ô∏è Ingeniero de Calidad de Datos (Data Quality Engineer)   |
| üí° Ingeniero de BI (Business Intelligence Engineer)          |
| üìà Analista de BI (Business Intelligence Analyst)            |
| üíº Consultor de Datos (Data Consultant)                     |

# Sistema de Perfilamiento de Datos para BigQuery

## Descripci√≥n del Proyecto
Este repositorio contiene un marco de trabajo automatizado dise√±ado para crear perfilamiento de datos de tablas almacenadas en Google BigQuery de manera masiva, completa, r√°pida y eficiente (puede ser aplicable tambi√©n a Athena de AWS con algunas modificaciones).

## :mag_right: An√°lisis Detallado y Calidad de datos
El proyecto incorpora funcionalidades avanzadas para generar consultas SQL detalladas y espec√≠ficas que se ejecutan en BigQuery. Estas consultas no solo contabilizan registros totales y nulos, sino que tambi√©n eval√∫an la integridad y la distribuci√≥n de los datos, incluyendo la identificaci√≥n de valores extremos y la realizaci√≥n de c√°lculos estad√≠sticos como promedios y conteos condicionales. Esto es esencial para garantizar que los datos no solo sean precisos, sino tambi√©n √∫tiles para tomar decisiones informadas e identifica posibles outliers.

## :hammer_and_wrench: Flexibilidad y Manejo Eficiente
Los datos pueden cargarse de fuentes diferentes mientas cumplan el formato del template como archivos CSV, Excel o googlesheet, adem√°s su capacidad para automatizar el desglose de grandes conjuntos de datos en m√∫ltiples partes facilita su manejo y an√°lisis para mejorar el rendimiento, manejo de recursos y control de limites que establece BigQuery.

## :handshake: Invitaci√≥n a Colaborar
Invito a todos los interesados en mejorar la calidad de sus datos y eficientizar sus procesos anal√≠ticos a conectarse conmigo para explorar posibles colaboraciones y oportunidades profesionales. Juntos, podemos transformar la manera en que interactuamos con los datos y liderar la pr√≥xima ola de innovaciones en la anal√≠tica de datos.

## :sparkles: Gracias por su atenci√≥n y espero poder conectar y colaborar con muchos de ustedes en el futuro pr√≥ximo. :sparkles:

## üìÅ Estructura de Archivos

Aseg√∫rate de tener estos archivos en tu directorio de trabajo:
- `perfilamiento_proyecto_dq_desktop.py`:  Este archivo contiene todo el c√≥digo necesario para ejecutar las consultas de perfilamiento en el escritorio con Python.
- `perfilamiento_proyecto_dq_gcolab.py`:  Este archivo contiene todo el c√≥digo necesario para ejecutar las consultas de perfilamiento en google colab.
- `plantilla_perfilamiento.csv`: Una plantilla CSV que define el esquema de los datos a analizar.
  
- ## Uso
- Modifica el archivo `perfilamiento_datos.csv` con los campos y par√°metros deseados para el perfilamiento.
- Ejecuta el script `perfilamiento_proyecto_dq.py` para generar las consultas SQL

## üó∫Ô∏è Gu√≠a Paso a Paso

### Paso 1: Preparar la Plantilla de Datos

1. Abre el archivo `perfilamiento_datos.csv` en un editor de texto o en una hoja de c√°lculo.
2. Edita las columnas seg√∫n los datos que necesitas perfilar:
   - **CAMPO**: Nombre del campo a analizar.
   - **TIPO**: Tipo de dato del campo (e.g., STRING, INTEGER).
   - **PARTICION**: Nombre de la columna de partici√≥n.
   - **TABLA**: Nombre de la tabla donde se encuentra el campo.
   - **Fecha_desde**: Fecha de inicio para el filtro de la consulta.
   - **Fecha_hasta**: Fecha de fin para el filtro de la consulta.

     Ejemplo del archivo:
     ![image](https://github.com/Cesarandres91/DQ_Perfilamiento_de_datos_en_Bigquery/assets/102868086/8fcbe9e9-3378-48cb-bdcc-04038de2ae87)


### Paso 2: Configuraci√≥n del Entorno

Aseg√∫rate de que tu entorno Python est√° configurado correctamente, siempre puedes ejecutarlo en googlecolab para evitar quebraderos de cabeza y verifica que tienes las credenciales necesarias para acceder a Google BigQuery.

### Paso 3: Ejecutar el Script

1. Abre tu terminal o l√≠nea de comandos.
2. Navega hasta el directorio donde se encuentran los archivos `perfilamiento_proyecto_dq.py` y `perfilamiento_datos.csv`.
3. Ejecuta el siguiente comando:
   ```bash
    perfilamiento_proyecto_dq_desktop.py
   ```
   o desde google colab puedes usar el otro c√≥digo
   
   ```bash
   perfilamiento_proyecto_dq_gcolab.py
   ```
   
El script leer√° la plantilla (recuerda ajustar el directorio), generar√° las consultas SQL en un archivo de texto que podr√°s copiar y pegar en BigQuery.

Ejemplo Query generada: 
``` Ejemplo_Query_generada.txt ```
![image](https://github.com/Cesarandres91/DQ_Perfilamiento_de_datos_en_Bigquery/assets/102868086/846bcea7-572f-4f27-be47-d41e990c5c3f)

PD: Las consultas est√°n particionadas en varios archivos en caso de que la cantidad de campos sea alta, para mejorar el rendimiento, manejo de recursos y control de limites que establece BigQuery, pero puedes modificarlo directamente en el c√≥digo en caso de que no lo necesites.

### Paso 4: Revisar los Resultados
Revisa los resultados de las consultas que se mostrar√°n en la salida est√°ndar o en los archivos de salida especificados en el script.
Analiza los datos para entender mejor la calidad y estructura de los datos en tu base de datos BigQuery.

![image](https://github.com/Cesarandres91/DQ_Perfilamiento_de_datos_en_Bigquery/assets/102868086/a87a847e-3a5a-44b0-ab85-20997af8381a)

![image](https://github.com/Cesarandres91/DQ_Perfilamiento_de_datos_en_Bigquery/assets/102868086/0121ddfc-0de8-41c9-a449-9ea17c2589eb)

### Visualizaci√≥n:
Ya con estos datos, solo queda generar las gr√°ficas con nuestra herramientas de inteligencia de negocio preferida o plataforma de visualizaci√≥n de datos,
generalmente en las compa√±√≠as utilizamos Tableau o Power BI para generar tableros de control utilizando como input la tabla final,
pero para este caso y no depender de ninguna licencia gener√© las gr√°ficas solu utilizando python, con estas librer√≠as:
```
import matplotlib.pyplot as plt
import seaborn as sns
# Configurar estilo de Seaborn
sns.set(style="whitegrid")
 ```
![Nulos](https://github.com/Cesarandres91/DQ_Perfilamiento_de_datos_en_Bigquery/assets/102868086/60a98605-165d-4d1a-87d0-7d6584313fb9)

![Distintos](https://github.com/Cesarandres91/DQ_Perfilamiento_de_datos_en_Bigquery/assets/102868086/4fad40d0-29c3-4a22-8047-16ecae79c166)

![Largo_maximo](https://github.com/Cesarandres91/DQ_Perfilamiento_de_datos_en_Bigquery/assets/102868086/2888a304-eccc-41dc-ab4e-78890a18537d)

![Largo_minimo](https://github.com/Cesarandres91/DQ_Perfilamiento_de_datos_en_Bigquery/assets/102868086/a735da08-c44f-41e0-8617-9fc2e050acc8)


üßê Soluci√≥n de Problemas
Si encuentras errores durante la ejecuci√≥n, verifica lo siguiente:
Que las credenciales de BigQuery est√°n configuradas correctamente.
Que los nombres de las columnas en perfilamiento_datos.csv coinciden exactamente con los de la base de datos.
Que tienes permisos suficientes en BigQuery para ejecutar consultas y acceder a las tablas especificadas.

## Caracter√≠sticas
- **Generaci√≥n Autom√°tica de Consultas SQL**: Scripts de Python leen especificaciones desde una hoja de Excel y generan consultas SQL.
- **Perfilamiento Personalizable**: Permite la personalizaci√≥n completa del perfilamiento basado en par√°metros definidos en la hoja de Excel.
- **Reportes de Calidad de Datos**: Genera m√©tricas de calidad de datos como registros correctos, errores y umbrales de calidad.

## Pre-requisitos
- Python 3.8 o superior.
- Acceso a Google BigQuery.
- Google Colab o un entorno Python local configurado.
- Paquete `pandas` instalado para la manipulaci√≥n de datos.
- Credenciales de Google Cloud con permisos adecuados para leer y ejecutar consultas en BigQuery.

## Configuraci√≥n
1. **Clonar el Repositorio**:

2. **Instalaci√≥n de Dependencias**:


3. **Configuraci√≥n de Credenciales de Google Cloud**:
- Aseg√∫rate de tener un archivo de credenciales de servicio de Google Cloud (JSON).
- Establece la variable de entorno `GOOGLE_APPLICATION_CREDENTIALS` apuntando al archivo JSON:
  ```
  export GOOGLE_APPLICATION_CREDENTIALS="path/to/your/credentials.json"
  ```


## Contribuci√≥n
Para contribuir al proyecto, por favor sigue los siguientes pasos:
- **Fork el Repositorio**: Haz un fork del proyecto a tu cuenta de GitHub.
- **Crea una Rama**: Crea una rama para tus cambios.
- **Haz tus Cambios**: A√±ade o mejora funcionalidades.
- **Env√≠a un Pull Request**: Env√≠a un PR para integrar tus cambios al repositorio principal.

## Licencia
Este proyecto est√° licenciado bajo la Licencia MIT - ver el archivo `LICENSE` para m√°s detalles.


